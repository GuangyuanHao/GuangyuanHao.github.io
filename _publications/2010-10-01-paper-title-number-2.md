---
title: "DSRGAN: Explicitly Learning Disentangled Representation of Underlying Structure and Rendering for Image Generation without Tuple Supervision"
collection: publications
permalink: 
excerpt: 'This paper is about explicitly learning disentangled representation. Present methods like infoGAN, Beta-VAE aim to maximum mutual information between latent variables and images in nature, so those methods make each dimension of the input prior represent one of unknown factors as fully as possible. Therefore, factors that they disentangle are random and ambiguous and thus those models do not always disentangle factors people care. My project aims to explicitly learn disentangled representation so as to improve model interpretability.'
date: 2019-06-16
venue: CVPR （if accepted）
paperurl: 
citation: 'Guangyuan Hao, Hongxing Yu, Weishi Zheng, &quot;DSRGAN: Explicitly Learning Disentangled Representation of Underlying Structure and Rendering for Image Generation without Tuple Supervision &quot; <i>Submitted to CVPR</i>, 2019.'
---
This paper is about explicitly learning disentangled representation. Present methods like infoGAN, Beta-VAE aim to maximum mutual information between latent variables and images in nature, so those methods make each dimension of the input prior represent one of unknown factors as fully as possible. Therefore, factors that they disentangle are random and ambiguous and thus those models do not always disentangle factors people care. My project aims to explicitly learn disentangled representation so as to improve model interpretability.

[Download paper here]('The link will be released after the paper is published.')
